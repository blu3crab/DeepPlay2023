# -*- coding: utf-8 -*-
"""aha-tf-style-xfer-multi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17tSaQUTL5XVZZ5V5gDiyeRJXwaVHx3Mm

Artistic Style Transfer with TensorFlow Lite
# https://www.tensorflow.org/lite/examples/style_transfer/overview?authuser=3
"""

import tensorflow as tf
print(tf.__version__)

import IPython.display as display

import matplotlib.pyplot as plt

import matplotlib as mpl
mpl.rcParams['figure.figsize'] = (12,12)
mpl.rcParams['axes.grid'] = False

import numpy as np
import time
import functools

import PIL

import io
from google.colab import files

import os
import shutil

from os import listdir
from os.path import isfile, join

from pathlib import Path


"""# Data Access Methods"""
#
# content_path = tf.keras.utils.get_file('belfry.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/belfry-2611573_1280.jpg')
# style_path = tf.keras.utils.get_file('style23.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/style23.jpg')
#
# style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite')
# style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite')
#
# content_path = files.upload()
# print(f"content_path->{content_path}")
# # style_path = files.upload()
# # print(f"style_path->{style_path}")
#
# style_path = "/content/style13.jpg"
# # content_path = "/content/PXL_20221223_034307654.jpg"
# content_path = "/content/Sketch 1-page-001.jpg"
#
# from google.colab import drive
# drive.mount('/content/gdrive')
#
# !ls /content/gdrive/MyDrive/TucDataSets/tf-style/styles
#
# !ls gdrive/MyDrive/TucDataSets/tf-style/content
#
# style_path = "/content/gdrive/MyDrive/TucDataSets/tf-style/styles/style1.jpg"
# style_path
#
# content_path = "/content/gdrive/MyDrive/TucDataSets/tf-style/content/PXL_20221223_034242926.jpg"
# content_path

"""# Standalone Functions"""

# Function to load an image from a file, and add a batch dimension.
def load_img(path_to_img):
  img = tf.io.read_file(path_to_img)
  img = tf.io.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32)
  img = img[tf.newaxis, :]

  return img

# Function to pre-process by resizing an central cropping it.
def preprocess_image(image, target_dim):
  # Resize the image so that the shorter dimension becomes 256px.
  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)
  short_dim = min(shape)
  scale = target_dim / short_dim
  new_shape = tf.cast(shape * scale, tf.int32)
  image = tf.image.resize(image, new_shape)

  # Central crop the image.
  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)

  return image

def imshow(image, title=None):
  if len(image.shape) > 3:
    image = tf.squeeze(image, axis=0)

  plt.imshow(image)
  if title:
    plt.title(title)

# Function to run style prediction on preprocessed style image.
def run_style_predict(preprocessed_style_image):
  # Load the model.
  interpreter = tf.lite.Interpreter(model_path=style_predict_path)

  # Set model input.
  interpreter.allocate_tensors()
  input_details = interpreter.get_input_details()
  interpreter.set_tensor(input_details[0]["index"], preprocessed_style_image)

  # Calculate style bottleneck.
  interpreter.invoke()
  style_bottleneck = interpreter.tensor(
      interpreter.get_output_details()[0]["index"]
      )()

  return style_bottleneck

# Run style transform on preprocessed style image
def run_style_transform(style_bottleneck, preprocessed_content_image):
  # Load the model.
  interpreter = tf.lite.Interpreter(model_path=style_transform_path)

  # Set model input.
  input_details = interpreter.get_input_details()
  interpreter.allocate_tensors()

  # Set model inputs.
  interpreter.set_tensor(input_details[0]["index"], preprocessed_content_image)
  interpreter.set_tensor(input_details[1]["index"], style_bottleneck)
  interpreter.invoke()

  # Transform content image.
  stylized_image = interpreter.tensor(
      interpreter.get_output_details()[0]["index"]
      )()

  return stylized_image

"""# Sample Cells per Image"""
#
# # Load the input images.
# content_image = load_img(content_path)
# style_image = load_img(style_path)
#
# # Preprocess the input images.
# preprocessed_content_image = preprocess_image(content_image, 384)
# preprocessed_style_image = preprocess_image(style_image, 256)
#
# print('Style Image Shape:', preprocessed_style_image.shape)
# print('Content Image Shape:', preprocessed_content_image.shape)
#
# plt.subplot(1, 2, 1)
# imshow(preprocessed_content_image, 'Content Image')
#
# plt.subplot(1, 2, 2)
# imshow(preprocessed_style_image, 'Style Image')
#
# # Calculate style bottleneck for the preprocessed style image.
# style_bottleneck = run_style_predict(preprocessed_style_image)
# print('Style Bottleneck Shape:', style_bottleneck.shape)
#
# # Stylize the content image using the style bottleneck.
# stylized_image = run_style_transform(style_bottleneck, preprocessed_content_image)
#
# # Visualize the output.
# imshow(stylized_image, 'Stylized Image')
#
# # export_image(stylized_image).save("stylized_image1.png")
# # export_image(stylized_image).save("stylized_image2.png")
# export_image(stylized_image).save("stylized_image3.png")
#
# !ls
# !ls sample_data
#
# # stylized_file = "/content/stylized_image1.png"
# #stylized_file = "/content/stylized_image2.png"
# stylized_file = "/content/stylized_image3.png"
# files.download(stylized_file)
#
# # Calculate style bottleneck of the content image.
# style_bottleneck_content = run_style_predict(
#     preprocess_image(content_image, 256))
#
# # Define content blending ratio between [0..1].
# # 0.0: 0% style extracts from content image.
# # 1.0: 100% style extracted from content image.
# #content_blending_ratio = 0.5
# content_blending_ratio = 0.7  # blends more from content
# #content_blending_ratio = 0.9  # blends mostly from content
# #content_blending_ratio = 0.1 # blends mostly from style
#
# # Blend the style bottleneck of style image and content image
# style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \
#                            + (1 - content_blending_ratio) * style_bottleneck
#
# # Stylize the content image using the style bottleneck.
# stylized_image_blended = run_style_transform(style_bottleneck_blended,
#                                              preprocessed_content_image)
#
# # Visualize the output.
# imshow(stylized_image_blended, 'Blended Stylized Image')
#
# !ls
#
# #export_image(stylized_image).save("stylized_image_blended1.png")
#
# export_image(stylized_image_blended).save("stylized_image_blended3.png")
# stylized_image_blended = "/content/stylized_image_blended3.png"
# files.download(stylized_image_blended)

"""# Generator Data Prep"""

from google.colab import drive
drive.mount('/content/gdrive')

# !pwd
#
# !ls /content
# !ls /content/sample_data
#
# !ls /content/gdrive/MyDrive/TucDataSets/tf-style/styles
#
# !ls gdrive/MyDrive/TucDataSets/tf-style/content

"""# Generator Fun"""

#import os, shutil
def delete_folder_contents(folder):
  #folder = '/path/to/folder'
  for filename in os.listdir(folder):
      file_path = os.path.join(folder, filename)
      try:
          if os.path.isfile(file_path) or os.path.islink(file_path):
              os.unlink(file_path)
          elif os.path.isdir(file_path):
              shutil.rmtree(file_path)
      except Exception as e:
          print('Failed to delete %s. Reason: %s' % (file_path, e))

def export_image(tf_img):
    tf_img = tf_img*255
    tf_img = np.array(tf_img, dtype=np.uint8)
    if np.ndim(tf_img)>3:
        assert tf_img.shape[0] == 1
        img = tf_img[0]
    return PIL.Image.fromarray(img)

def load_image(content_path, style_path):
  # Load the input images.
  content_image = load_img(content_path)
  style_image = load_img(style_path)
  return content_image, style_image

def preprocess(content_image, style_image):
  # Load the input images.
  content_image = load_img(content_path)
  style_image = load_img(style_path)

  # Preprocess the input images.
  preprocessed_content_image = preprocess_image(content_image, 384)
  preprocessed_style_image = preprocess_image(style_image, 256)

  #print('Style Image Shape:', preprocessed_style_image.shape)
  #print('Content Image Shape:', preprocessed_content_image.shape)

  return preprocessed_content_image, preprocessed_style_image

def show_preprocess(preprocessed_content_image, preprocessed_style_image, row = 1):
  plt.subplot(1, 2, 1)
  imshow(preprocessed_content_image, 'Content Image')

  plt.subplot(1, 2, 2)
  imshow(preprocessed_style_image, 'Style Image')

def bottleneck(preprocessed_content_image, preprocessed_style_image):
  # Calculate style bottleneck for the preprocessed style image.
  style_bottleneck = run_style_predict(preprocessed_style_image)
  #print('Style Bottleneck Shape:', style_bottleneck.shape)  

  # Stylize the content image using the style bottleneck.
  stylized_image = run_style_transform(style_bottleneck, preprocessed_content_image)

  # Visualize the output.
  #imshow(stylized_image, 'Stylized Image')

  return stylized_image, style_bottleneck

def blend(content_image, style_bottleneck, preprocessed_content_image):
  # Calculate style bottleneck of the content image.
  style_bottleneck_content = run_style_predict(preprocess_image(content_image, 256))
  
  # Define content blending ratio between [0..1].
  # 0.0: 0% style extracts from content image.
  # 1.0: 100% style extracted from content image.
  #content_blending_ratio = 0.5
  content_blending_ratio = 0.7  # blends more from content

  # Blend the style bottleneck of style image and content image
  style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \
                            + (1 - content_blending_ratio) * style_bottleneck

  # Stylize the content image using the style bottleneck.
  stylized_image_blended = run_style_transform(style_bottleneck_blended,
                                              preprocessed_content_image)
  return stylized_image_blended

"""# Run Generator"""

# download tfhub style & transfer
style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite')
style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite')

style_dir = "/content/gdrive/MyDrive/TucDataSets/tf-style/styles/"
print(f"style_dir->", style_dir)

style_list = [f for f in listdir(style_dir) if isfile(join(style_dir, f))]
print(f"style_list->", style_list)

content_dir = "/content/gdrive/MyDrive/TucDataSets/tf-style/content/"
print(f"content_dir->", content_dir)

content_list = [f for f in listdir(content_dir) if isfile(join(content_dir, f))]
print(f"content_list->", content_list)

# from pathlib import Path
Path("/content/stylized_image_dir").mkdir(parents=True, exist_ok=True)

output_dir = "/content/stylized_image_dir/"
delete_folder_contents(output_dir)
# content_path = "/content/gdrive/MyDrive/TucDataSets/tf-style/content/PXL_20221223_034242926.jpg"
# print(f"content_path->", content_path)

for content in content_list:
  content_path = content_dir + content
  content_base_name = content.split('.')[0]
  style_count = 0
  # iterate through styles list generating stylized images & blended images
  for style in style_list:

    style_count = style_count + 1
    style_path = style_dir + style
    print(f"style_path->", style_path)
    content_image, style_image = load_image(content_path, style_path)
    preprocessed_content_image, preprocessed_style_image = preprocess(content_image, style_image)

    stylized_image, style_bottleneck = bottleneck(preprocessed_content_image, preprocessed_style_image)

    stylized_name = content_base_name + "_style" + str(style_count) + ".png"
    export_image(stylized_image).save("/content/stylized_image_dir/" + stylized_name)

    stylized_image_blended = blend(content_image, style_bottleneck, preprocessed_content_image)
    blended_name = content_base_name + "_blended_" + "style" + str(style_count) + ".png"
    export_image(stylized_image_blended).save("/content/stylized_image_dir/" + blended_name)
    if style_count > 1:
      break

# zip_filename_base = "stylized_image_dir"
# target_dir = "/content/stylized_image_dir"
# shutil.make_archive(zip_filename_base, 'zip', target_dir)
#
# zip_filename = "stylized_image_dir" + ".zip"
# files.download(zip_filename)

#!rm /content/*.png
#!rm /content/*.zip
# !ls -l /content/
# !ls /content/stylized_image_dir/

# import shutil
# zip_filename_base = "stylized_image_dir"
# target_dir = "/content/stylized_image_dir"
# shutil.make_archive(zip_filename_base, 'zip', target_dir)

# zip_filename = "stylized_image_dir" + ".zip"
# files.download(zip_filename)

# !ls /content/stylized_image_dir/
# output_dir = "/content/stylized_image_dir/"
# delete_folder_contents(output_dir)
# !ls /content/stylized_image_dir/