{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#kaggle api token\nimport tensorflow as tf\n\n# Import the American Sign Language digits database\nimport kaggle.datasets as datasets\n\n# Specify the directory where the dataset will be downloaded\n#dataset_dir = '/path/to/sign_language_digits/'\ndataset_dir = './data/sign_language_digits/'\n\n# Download the dataset\n#datasets.load_dataset('ardamavi/sign_language_digits', data_dir=dataset_dir, api_key='<your_api_token>')\ndatasets.load_dataset('ardamavi/sign_language_digits', data_dir=dataset_dir, api_key='ebdee7b9eb97fe61d9250572fe9b2730')\n\n# Load the training and test sets\n(train_images, train_labels), (test_images, test_labels) = datasets.load_dataset('ardamavi/sign_language_digits', split='train', download=True, api_key='<your_api_token>')\n\n# Scale the images to a range of 0 to 1\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0\n\n# Create the model\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_images, train_labels, epochs=10)\n\n# Evaluate the model\nmodel.evaluate(test_images, test_labels)\n\n# Save the model\nmodel.save('hand_sign_classification_model.h5')","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}