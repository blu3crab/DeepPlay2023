{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **aha-sleep-fe-cnn**\n**sleep event** transforms - read event csv with converters\n1. remove rows with NANs\n2. transform timestamp -> uint32 minutes past 2017-01-01\n3. transform event from text to enum (NAN, **ONSET**, SLEEP, **WAKEUP**, WAKE)\n4. drop \"step\"\n5. drop \"night\"\n**series parquet** transforms - read series parquet with transforms\n1. remove rows with NANs\n2. transform timestamp -> uint32 minutes past 2017-01-01\n3. transform zangle -> uint16 zangle\n4. transform enmo -> uint16 enmo * 1000\n**feature label** generation\n<br>generate labels for series - X_train series, Y labels\n```\nfor each series_id \n    set event onset time\n    set event wakeup time\n    for each series row\n        if series time < event wakeup time\n            series row label = SLEEP\n        else if series time = event wakeup time\n            series row label = WAKEUP\n        else if series time > event wakeup time AND series time < event onset time\n            series row label = WAKE\n        else if series time = event onset time\n            series row label = ONSET\n```\n\n**model** \n1. train CNN using X_train, Y labels\n2. optimize learning rate\n3. forecast\n4. evaluate\n\n\n ","metadata":{}},{"cell_type":"code","source":"!pip install icecream","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time\nimport seaborn as sns\nimport pyarrow.parquet as pq\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from icecream import ic\nic(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################################################################\nimport wandb\n#wandb_enabled = True       # on -> interactive\nwandb_enabled = False     # off -> submission\n\nif wandb_enabled:\n    wandb.login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read raw csv & print all rows\n# train_events = pd.read_csv('/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv')\n# pd.set_option('display.max_rows', None)\n# train_events","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################################################################\nfrom types import SimpleNamespace\ntuner = SimpleNamespace(\n    # column labels\n    SERIES_ID_COLUMN = 'series_id',\n    NIGHT_COLUMN = 'night',\n    EVENT_COLUMN = 'event',\n    STEP_COLUMN = 'step',\n    TIME_COLUMN = 'timestamp',\n\n    NAN_TIME = 0,\n\n    ANGLEZ_COLUMN = 'anglez',\n    ENMO_COLUMN = 'enmo',\n\n    # event labels\n    ONSET_EVENT_LABEL = 'onset',\n    WAKEUP_EVENT_LABEL = 'wakeup',\n\n    # event enumeration\n    NAN_EVENT = 0,\n    ONSET_EVENT = 1,\n    SLEEP_EVENT = 2,\n    WAKEUP_EVENT = 3,\n    WAKE_EVENT = 4\n)\nic(tuner)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# converters\nConverters\n==========\n## remove_rows_with_nan\n## convert_to_minutes\n## convert_event_enumeration","metadata":{}},{"cell_type":"code","source":"import datetime\n\ndef remove_rows_with_nan(row):\n  \"\"\"Removes rows with NaN.\n\n  Args:\n    row: A Pandas Series object representing the current row of the CSV file.\n\n  Returns:\n    None if the row contains NaN, otherwise the row.\n  \"\"\"\n\n  if row.isna().any():\n    return None\n  else:\n    return row\n\ndef convert_to_seconds(date_string):\n    \"\"\"Converts a date string to seconds past 2017-01-01.\n\n    Args:\n    date_string: A string in the format YYYY-MM-DDTHH:MM:SS-TZ.\n\n    Returns:\n    An integer representing the number of seconds since 2017-01-01.\n    \"\"\"\n    #print(f\"date_string->,{date_string}\")\n    if len(date_string) == 0:\n        return None # NAN_TIME\n    \n    # 2018-08-14T22:26:00-0400\n    date_time = datetime.datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S-%f\")\n    time_in_seconds = np.int32((date_time - datetime.datetime(2017, 1, 1)).total_seconds())\n    #print(time_in_minutes)\n    return time_in_seconds \n\ndef convert_to_minutes(date_string):\n    \"\"\"Converts a date string to minutes past 2017-01-01.\n\n    Args:\n    date_string: A string in the format YYYY-MM-DDTHH:MM:SS-TZ.\n\n    Returns:\n    An integer representing the number of minutes since 2017-01-01.\n    \"\"\"\n    #print(f\"date_string->,{date_string}\")\n    if len(date_string) == 0:\n        return None # NAN_TIME\n    \n    # 2018-08-14T22:26:00-0400\n    date_time = datetime.datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S-%f\")\n    #return (date_time - datetime.datetime(2018, 1, 1)).total_seconds() // 60\n    #return np.int32((date_time - datetime.datetime(2017, 1, 1)).total_seconds() // 60)\n    time_in_minutes = np.int32((date_time - datetime.datetime(2017, 1, 1)).total_seconds() // 60)\n    #print(time_in_minutes)\n    return time_in_minutes \n\n\ndef convert_event_enumeration(event_string):\n    if event_string == tuner.ONSET_EVENT_LABEL:\n        return tuner.ONSET_EVENT\n    elif event_string == tuner.WAKEUP_EVENT_LABEL:\n        return tuner.WAKEUP_EVENT\n    return tuner.NAN_EVENT  \n\ndef convert_zangle(zangle_string):\n    zangle_float = np.float32(zangle_string)\n    zangle = np.int16(zangle_float)\n\n    return zangle\n\ndef convert_enmo(enmo_string):\n    enmo_float = np.float32(enmo_string)\n    enmo = np.uint16(enmo_float*1000)\n\n    return enmo\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unit test converters\nprint(convert_to_seconds('2018-08-14T22:26:00-0400'))\nprint(convert_to_seconds(''))\nprint(convert_to_minutes('2018-08-14T22:26:00-0400'))\nprint(convert_to_minutes(''))\n\nprint(convert_to_seconds('2018-09-06T04:59:55-0400'))\nduration = convert_to_seconds('2018-09-06T04:59:55-0400') - convert_to_seconds('2018-08-14T22:26:00-0400')\nprint(f\"begin-end-trial event duration (seconds)->{duration}\")\n\nprint(convert_event_enumeration('onset'))\nprint(convert_event_enumeration('wakeup'))\nprint(convert_event_enumeration('dunno'))\n\nprint(convert_zangle('2.636700'))\nprint(convert_zangle('-90.636700'))\n\nprint(convert_enmo('0.0216'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"event_converters = {tuner.TIME_COLUMN: convert_to_seconds, tuner.EVENT_COLUMN: convert_event_enumeration}\n#event_converters = {tuner.TIME_COLUMN: convert_to_minutes, tuner.EVENT_COLUMN: convert_event_enumeration}\n# converters = {'timestamp': convert_to_minutes, 'event': convert_event_enumeration}\n#converters = {'remove_rows_with_nan': {STEP_COLUMN: remove_rows_with_nan, TIME_COLUMN: remove_rows_with_nan}, TIME_COLUMN: convert_to_minutes, EVENT_COLUMN: convert_event_enumeration}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_event = pd.read_csv('/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv', \n                          converters=event_converters)\nprint(f\"raw # event rows - > {len(train_event)}\")\n# drop NAN rows\ntrain_event = train_event.dropna(axis=0)\nprint(f\"drop NAN # event rows - > {len(train_event)}\")\n# Re-index the DataFrame\ntrain_event = train_event.reset_index(drop=True)\n\n# drop night, step columns\ntrain_event = train_event.drop(tuner.NIGHT_COLUMN, axis=1)\ntrain_event = train_event.drop(tuner.STEP_COLUMN, axis=1)\n\ntrain_event[tuner.TIME_COLUMN] = train_event[tuner.TIME_COLUMN].astype('uint32')\nprint(train_event.iloc[0])\nprint(train_event[tuner.TIME_COLUMN].dtype)\n\n#pd.set_option('display.max_rows', None)\npd.set_option('display.max_rows', 64)\ntrain_event","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_id_filter = train_event.loc[0]['series_id']\nic(series_id_filter)\nseries_id_list = train_event['series_id']\nseries_id_unique_list = train_event['series_id'].unique()\nic(len(series_id_list),len(series_id_unique_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_event_filter = train_events.loc[(train_events['series_id'] == train_events.loc[0]['series_id'])]\ntrain_event_filter = train_event.loc[(train_event['series_id'] == series_id_filter)]\nic(len(train_event_filter))\npd.set_option('display.max_rows', None)\ntrain_event_filter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Series\n* metrics at 5 sec intervals\n* ~86,400 per day (NAN rows will be deleted)\n","metadata":{}},{"cell_type":"code","source":"parquet_train_series = '/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet'\n#train_series = pq.read_table(parquet_train_series).to_pandas()\n\ntrain_series = pq.read_table(parquet_train_series,\n                             filters=[[('series_id', '=', series_id_filter)],]).to_pandas()\nic(series_id_filter)\npd.set_option('display.max_rows', 128)\ntrain_series","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"raw # train_series rows - > {len(train_series)}\")\n# drop NAN rows\ntrain_series = train_series.dropna(axis=0)\nprint(f\"drop NAN # train_series rows - > {len(train_series)}\")\n# drop step column\nprint(train_series.columns)\ntrain_series = train_series.drop(tuner.STEP_COLUMN, axis=1)\ntrain_series","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_series_x = train_series\n# train_series_x[tuner.TIME_COLUMN] = train_series_x[tuner.TIME_COLUMN].apply(convert_to_seconds)\n# train_series_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_series_x = train_series\ntrain_series_x[tuner.TIME_COLUMN] = train_series_x[tuner.TIME_COLUMN].apply(convert_to_seconds)\ntrain_series_x[tuner.ANGLEZ_COLUMN] = train_series[tuner.ANGLEZ_COLUMN].apply(convert_zangle)\ntrain_series_x[tuner.ENMO_COLUMN] = train_series[tuner.ENMO_COLUMN].apply(convert_enmo)\ntrain_series_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reset train series to transform\n# train_series = train_series_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trace event & series related info\ndef trace_event_series_snapshot(event_inx, event_onset_time, event_wakeup_time,\\\n                              series_inx, series_time, series_label):\n    ic(event_inx, event_onset_time, event_wakeup_time)\n    ic(series_inx-1, series_time, series_label[series_inx-1])\n    ic(series_inx, series_time, series_label[series_inx])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_series(series_id_list,train_event,train_series_x):\n    event_inx = 0\n    series_inx = 0\n    event_onset_time = 0\n    event_wakeup_time = 0\n    event_detected = False\n    ic(event_inx, event_onset_time, event_wakeup_time)\n    INTERVAL = 5 # 5 second intervals\n    series_label = []\n\n    # series_id 038441c925bb\n    # train_event_filter_limit = 38\n    # train_series_x_limit = 389879\n\n    train_event_filter_limit = len(train_event)\n    train_series_x_limit = len(train_series_x)\n    ic(train_event_filter_limit, train_series_x_limit)\n\n    #df.at[index, 'col_name'] = x\n\n    ic(series_id_list)\n    for series_id in series_id_list:\n        ic(series_id)\n        #while event_inx < train_event_filter_limit and \\\n        while series_inx < train_series_x_limit and \\\n            train_event.at[event_inx, tuner.SERIES_ID_COLUMN] == series_id and \\\n            train_series_x.at[series_inx, tuner.SERIES_ID_COLUMN] == series_id:\n\n            if not event_detected:\n                if train_event.at[event_inx, tuner.EVENT_COLUMN] == tuner.ONSET_EVENT:\n                    event_onset_time = train_event.at[event_inx, tuner.TIME_COLUMN]\n                    event_detected = True\n                elif train_event.at[event_inx, tuner.EVENT_COLUMN] == tuner.WAKEUP_EVENT:\n                    event_wakeup_time = train_event.at[event_inx, tuner.TIME_COLUMN]\n                    event_detected = True\n                #ic(event_inx, event_onset_time, event_wakeup_time)\n\n            series_time = train_series_x.at[series_inx, tuner.TIME_COLUMN]\n            #ic(series_inx, series_time)\n            if series_time > event_wakeup_time and series_time < event_onset_time:\n                series_label.append(tuner.WAKE_EVENT)\n                \n            elif series_time > event_onset_time and series_time < event_wakeup_time:\n                series_label.append(tuner.SLEEP_EVENT)\n                \n            elif series_time > event_wakeup_time and series_time > event_onset_time:\n                # prevent event_inx advancing past EOF\n                if event_inx + 1 < len(train_event):\n                    event_inx = event_inx + 1\n                    if series_label[series_inx-1] == tuner.WAKE_EVENT:\n                        series_label.append(tuner.ONSET_EVENT)\n                    elif series_label[series_inx-1] == tuner.SLEEP_EVENT:\n                        series_label.append(tuner.WAKEUP_EVENT)\n                # last event at EOF\n                else:\n                    if series_label[series_inx-1] == tuner.WAKEUP_EVENT or\\\n                    series_label[series_inx-1] == tuner.WAKE_EVENT: \n                        series_label.append(tuner.WAKE_EVENT)\n                    elif series_label[series_inx-1] == tuner.ONSET_EVENT or\\\n                    series_label[series_inx-1] == tuner.SLEEP_EVENT:\n                        series_label.append(tuner.SLEEP_EVENT)\n\n                event_detected = False\n\n                trace_event_series_snapshot(event_inx, event_onset_time, event_wakeup_time,\\\n                                           series_inx, series_time, series_label)\n                \n            elif series_time == event_onset_time:\n                series_label.append(tuner.ONSET_EVENT)\n                # prevent event_inx advancing past EOF\n                if event_inx + 1 < len(train_event):\n                    event_inx = event_inx + 1\n                event_detected = False\n\n                trace_event_series_snapshot(event_inx, event_onset_time, event_wakeup_time,\\\n                                           series_inx, series_time, series_label)\n                \n            elif series_time == event_wakeup_time: \n                series_label.append(tuner.WAKEUP_EVENT)\n                # prevent event_inx advancing past EOF\n                if event_inx + 1 < len(train_event):\n                    event_inx = event_inx + 1\n                event_detected = False\n\n                trace_event_series_snapshot(event_inx, event_onset_time, event_wakeup_time,\\\n                                           series_inx, series_time, series_label)\n\n            series_inx = series_inx + 1\n    return series_label    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# series time = onset or wakeup event time\n# dummy_series_list = [['038441c925bb', 51031800, 2, 21],\\\n#                 ['038441c925bb', 51031805, 2, 21],\\\n#                 ['038441c925bb', 51056760, 2, 21],\\\n#                 ['038441c925bb', 51057000, 2, 21],\\\n#                 ['038441c925bb', 51067800, 2, 21],\\\n#                 ['038441c925bb', 51086460, 2, 21],\\\n#                 ['038441c925bb', 51087460, 2, 21],\\\n#                 ['038441c925bb', 51088460, 2, 21],\\\n#                 ['038441c925bb', 51133020, 2, 21],\\\n#                 ['038441c925bb', 51143020, 2, 21],\\\n#                 ['038441c925bb', 51153020, 2, 21],\\\n#                ]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column_headers = list(train_series_x.columns.values)\n# ic(column_headers)\n# # series time != onset or wakeup event time\n# dummy_series_list = [['038441c925bb', 51031800, 2, 21],\\\n#                 ['038441c925bb', 51031805, 2, 21],\\\n#                 ['038441c925bb', 51056761, 2, 21],\\\n#                 ['038441c925bb', 51057000, 2, 21],\\\n#                 ['038441c925bb', 51067800, 2, 21],\\\n#                 ['038441c925bb', 51086461, 2, 21],\\\n#                 ['038441c925bb', 51087460, 2, 21],\\\n#                 ['038441c925bb', 51088460, 2, 21],\\\n#                 ['038441c925bb', 51133021, 2, 21],\\\n#                 ['038441c925bb', 51143020, 2, 21],\\\n#                 ['038441c925bb', 51153020, 2, 21],\\\n#                ]\n# dummy_series_array = np.array(dummy_series_list)\n# dummy_series_df = pd.DataFrame(dummy_series_array, columns=column_headers)\n# dummy_series_df[tuner.TIME_COLUMN] = dummy_series_df[tuner.TIME_COLUMN].astype('uint32')\n# ic(dummy_series_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label series\nseries_id_list = ['038441c925bb']\nseries_label_list = label_series(series_id_list, train_event_filter, train_series_x)\n# dummy series\n#series_label_list = label_series(series_id_list, train_event, dummy_series_df)\n#ic(series_label_list)\nseries_label_array = np.array(series_label_list)\nseries_label = pd.DataFrame(series_label_array)\n#series_label\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pwd\nseries_label.to_csv('/kaggle/working/series_label.csv', index=False)\n!ls -l\n!pwd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef download_local_csv_file(file_name, kaggle_working_dir):\n  \"\"\"Downloads a local CSV file to the Kaggle/working directory.\n\n  Args:\n    file_name: The name of the local CSV file.\n    kaggle_working_dir: The path to the Kaggle/working directory.\n  \"\"\"\n\n  # Copy the local CSV file to the Kaggle/working directory.\n  os.system(f\"cp {file_name} {kaggle_working_dir}\")\n\n# Get the path to the Kaggle/working directory.\nkaggle_working_dir = os.getcwd()\n\n# Download the local CSV file to the Kaggle/working directory.\ndownload_local_csv_file('series_label.csv', kaggle_working_dir)\n\n# Print a message confirming that the file was downloaded.\nprint(f'File data.csv downloaded successfully to {kaggle_working_dir}.')\n\n# Python\n# from kaggle.api.kaggle_api_extended import KaggleApi\n\n# # Create a Kaggle API object.\n# api = KaggleApi()\n\n# # Get the path to the Kaggle/working directory.\n# kaggle_working_dir = api.get_working_directory()\n\n# # Upload the local CSV file to the Kaggle/working directory.\n# api.upload_file(file_name, kaggle_working_dir)\n\n# # Print a message confirming that the file was uploaded.\n# print(f'File {file_name} uploaded successfully to {kaggle_working_dir}.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_train = train_series_x.to_numpy()\n# y_train = series_label.to_numpy()\nx_train = train_series_x\ny_train = series_label\nic(len(x_train), len(y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Define the CNN architecture\nclass CNN(tf.keras.Model):\n    def __init__(self):\n        super(CNN, self).__init__()\n\n        # Define the convolutional layers\n        self.conv1 = tf.keras.layers.Conv1D(32, 3, activation='relu')\n        self.conv2 = tf.keras.layers.Conv1D(64, 3, activation='relu')\n\n        # Define the pooling layers\n        self.pool1 = tf.keras.layers.MaxPooling1D(2)\n        self.pool2 = tf.keras.layers.MaxPooling1D(2)\n\n        # Define the fully connected layers\n        self.fc1 = tf.keras.layers.Dense(128, activation='relu')\n        self.fc2 = tf.keras.layers.Dense(4, activation='softmax')\n\n    def call(self, inputs):\n        # Pass the inputs through the convolutional and pooling layers\n        x = self.conv1(inputs)\n        x = self.pool1(x)\n        x = self.conv2(x)\n        x = self.pool2(x)\n\n        # Flatten the output of the pooling layer\n        x = tf.keras.layers.Flatten()(x)\n\n        # Pass the flattened output through the fully connected layers\n        x = self.fc1(x)\n        x = self.fc2(x)\n\n        return x\n\n# Create a CNN model\nmodel = CNN()\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model on the data\nmodel.fit(x_train, y_train, epochs=10)\n\n# Evaluate the model on the test data\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}